{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(); sns.set_style('dark')\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (_, _) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_class = 3\n",
    "cat_images = x_train[y_train.flatten() == cat_class]\n",
    "\n",
    "# Normalize the images to [-1, 1] for generator's tanh activation\n",
    "cat_images = (cat_images.astype('float32') - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(8 * 8 * 256, input_dim=latent_dim),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "    tf.keras.layers.Reshape((8, 8, 256)),  # Reshape to 8x8x256\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "    tf.keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'),  # Upsample to 16x16x128\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "    tf.keras.layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'),  # Upsample to 32x32x64\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "    tf.keras.layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding='same', activation='tanh')  # Output 32x32x3 image\n",
    "])\n",
    "\n",
    "discriminator = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (real/fake)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_gan(generator, discriminator):\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "    discriminator.trainable = False  # Freeze discriminator when training the generator\n",
    "    gan = tf.keras.Sequential([generator, discriminator])\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = compile_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_images(epoch, generator, examples=16, dim=(4, 4), figsize=(6, 6)):\n",
    "    noise = np.random.normal(0, 1, (examples, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5  # Rescale to [0, 1]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(examples):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"generated/generated_image_epoch_{epoch}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(epochs, batch_size, interval):\n",
    "    real = np.ones((batch_size, 1))  # Labels for real images\n",
    "    fake = np.zeros((batch_size, 1))  # Labels for fake images\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train Discriminator\n",
    "        idx = np.random.randint(0, cat_images.shape[0], batch_size)\n",
    "        real_images = cat_images[idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_images = generator.predict(noise)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, real)\n",
    "\n",
    "        # Print progress\n",
    "        if epoch % interval == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, D Loss: {d_loss[0]:.4f}, D Acc: {d_loss[1]:.4f}, G Loss: {g_loss:.4f}\")\n",
    "            save_generated_images(epoch, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the DCGAN\n",
    "train_gan(epochs=10000, batch_size=64, interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "examples = 16\n",
    "\n",
    "noise = np.random.normal(0, 1, (examples, latent_dim))\n",
    "\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "for i in range(examples):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('generated_images.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
