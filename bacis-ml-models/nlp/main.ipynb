{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as pltk\n",
    "import seaborn as sns; sns.set(); sns.set_style('dark')\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "grammar = {'t': [\"S\", \"X\"],\n",
    "          'S': [\"S\", \"X\"],\n",
    "          'T': [\"T\", \"V\"],\n",
    "          'x': [\"T\", \"V\"],\n",
    "          'V': [\"p\", \"v\"],\n",
    "          'p': [\"s\", \"x\"],\n",
    "          'P': [\"T\", \"V\"],\n",
    "          'X': [\"x\", \"s\"],\n",
    "          's': [\"E\"], \n",
    "          'v': [\"E\"]}\n",
    "def micro_reber_gram_gen():\n",
    "    seq = [\"B\", choice([\"t\", \"P\"])] \n",
    "    last = seq[-1]\n",
    "    \n",
    "    while last != 'E':\n",
    "        seq.append(choice(grammar[last]))\n",
    "        last = seq[-1]\n",
    "    \n",
    "    return ''.join(seq).upper()\n",
    "\n",
    "def reber_gram_generator():\n",
    "     c = choice([\"T\", \"P\"])\n",
    "     return \"B\" + c + micro_reber_gram_gen() + c + \"E\"\n",
    "\n",
    "\n",
    "POSSIBLE_CHARS = \"BEPSTVX\"\n",
    "MAX_LENGTH = 50\n",
    "def generate_corrupted_string():\n",
    "     good_string = reber_gram_generator()\n",
    "     index = np.random.randint(len(good_string))\n",
    "     good_char = good_string[index]\n",
    "     bad_char = np.random.choice(sorted(set(POSSIBLE_CHARS) - set(good_char)))\n",
    "     return good_string[:index] + bad_char + good_string[index + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BPBTSXXVPSEPE', 'BTBTXSEBE')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reber_gram_generator(), generate_corrupted_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_ids(s, chars=POSSIBLE_CHARS):\n",
    "    return [chars.index(c) for c in s]\n",
    "\n",
    "def generate_dataset(size):\n",
    "    good_strings = [\n",
    "        string_to_ids(reber_gram_generator())\n",
    "        for _ in range(size // 2)\n",
    "    ]\n",
    "    bad_strings = [\n",
    "        string_to_ids(generate_corrupted_string())\n",
    "        for _ in range(size - size // 2)\n",
    "    ]\n",
    "    all_strings = good_strings + bad_strings\n",
    "    X = tf.ragged.constant(all_strings, ragged_rank=1)\n",
    "    y = np.array([[1.] for _ in range(len(good_strings))] +\n",
    "                 [[0.] for _ in range(len(bad_strings))])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[0, 4, 0, 4, 3, 6, 6, 4, 4, 4, 4, 4, 5, 2, 6, 4, 5, 2, 6, 4, 5, 2, 6, 5, 2,\n",
       "  3, 1, 4, 1]                                                               ,\n",
       " [0, 4, 0, 2, 4, 5, 5, 1, 4, 1], [0, 2, 0, 2, 5, 5, 1, 2, 1], ...,\n",
       " [0, 2, 0, 4, 6, 3, 1, 2, 4],\n",
       " [0, 4, 0, 2, 4, 1, 4, 5, 2, 6, 5, 2, 6, 4, 5, 5, 1, 4, 1],\n",
       " [0, 2, 1, 4, 3, 3, 3, 3, 3, 3, 3, 6, 3, 1, 2, 1]]>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = generate_dataset(10000)\n",
    "X_valid, y_valid = generate_dataset(2000)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(29,), dtype=int32, numpy=\n",
       "array([0, 4, 0, 4, 3, 6, 6, 4, 4, 4, 4, 4, 5, 2, 6, 4, 5, 2, 6, 4, 5, 2,\n",
       "       6, 5, 2, 3, 1, 4, 1])>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
    "    tf.keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS),\n",
    "                              output_dim=5),\n",
    "    tf.keras.layers.GRU(30),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.02, momentum = 0.95,\n",
    "                                    nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yardz\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_15/gru_9/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_15/gru_9/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_15/gru_9/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 11ms/step - loss: 0.6924 - accuracy: 0.5240 - val_loss: 0.6787 - val_accuracy: 0.4835\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6613 - accuracy: 0.5808 - val_loss: 0.6518 - val_accuracy: 0.4610\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6456 - accuracy: 0.5902 - val_loss: 0.6470 - val_accuracy: 0.6200\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6260 - accuracy: 0.6151 - val_loss: 0.5999 - val_accuracy: 0.6580\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.5813 - accuracy: 0.6664 - val_loss: 0.5548 - val_accuracy: 0.7095\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.5028 - accuracy: 0.7454 - val_loss: 0.4128 - val_accuracy: 0.8300\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2695 - accuracy: 0.9008 - val_loss: 0.1392 - val_accuracy: 0.9595\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.1856 - accuracy: 0.9317 - val_loss: 0.3411 - val_accuracy: 0.8565\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.1757 - accuracy: 0.9434 - val_loss: 0.0699 - val_accuracy: 0.9840\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0306 - accuracy: 0.9928 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 7.0708e-04 - accuracy: 1.0000 - val_loss: 5.7775e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 4.7486e-04 - accuracy: 1.0000 - val_loss: 4.1883e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 3.7574e-04 - accuracy: 1.0000 - val_loss: 3.5052e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 3.1466e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9980\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 2.7048e-04 - accuracy: 1.0000 - val_loss: 2.5955e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 2.3879e-04 - accuracy: 1.0000 - val_loss: 2.2928e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 2.1397e-04 - accuracy: 1.0000 - val_loss: 2.0637e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 1.9309e-04 - accuracy: 1.0000 - val_loss: 1.8975e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated probability that these are Reber strings:\n",
      "BPBPTVVEXE: 0.00%\n",
      "BPBTSSSSSSSSXXVVEPE: 99.97%\n"
     ]
    }
   ],
   "source": [
    "test_strings = [generate_corrupted_string(), reber_gram_generator()]\n",
    "X_test = tf.ragged.constant([string_to_ids(s) for s in test_strings], ragged_rank=1)\n",
    "\n",
    "y_proba = model.predict(X_test)\n",
    "print()\n",
    "print(\"Estimated probability that these are Reber strings:\")\n",
    "for index, string in enumerate(test_strings):\n",
    "    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
